# ─── LLM Model ───────────────────────────────────────────────────────────────
# LiteLLM model string: <provider>/<model-name>
# Change this one line to switch providers — no code changes needed.
#
# Examples:
#   openai/gpt-4o-mini                   (default)
#   openai/gpt-4o
#   anthropic/claude-3-5-haiku-20241022
#   anthropic/claude-3-5-sonnet-20241022
#   ollama/llama3.2                      (requires local Ollama server)
#   gemini/gemini-1.5-flash              (requires GEMINI_API_KEY)
#
# Full provider list: https://docs.litellm.ai/docs/providers
LLM_MODEL=openai/gpt-4o-mini

LLM_TEMPERATURE=0.0           # Keep at 0 for deterministic, factual output.

# ─── API Keys ────────────────────────────────────────────────────────────────
# Set the key for the provider you selected above. Others can be left blank.
OPENAI_API_KEY=sk-...
# ANTHROPIC_API_KEY=sk-ant-...
# GEMINI_API_KEY=...

# ─── Agent / API ─────────────────────────────────────────────────────────────
MAX_RETRIES=3                 # Max retrieval retries before the agent gives up.
API_BASE_URL=http://api:8000  # FastAPI backend URL (for Streamlit frontend).
